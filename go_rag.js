import { ChromaClient, OpenAIEmbeddingFunction } from "chromadb";
import { ChatOpenAI } from "@langchain/openai";
import { program } from "commander";
import * as dotenv from "dotenv";

dotenv.config();

const CHROMA_DB_URL = process.env.CHROMA_DB_URL || "http://localhost:8000";
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

if (!OPENAI_API_KEY) {
	console.error("‚ö†Ô∏è  FALTA API KEY: Debes configurar OPENAI_API_KEY en tu .env");
	process.exit(1);
}

// üìå Configurar CLI con Commander
program
	.version("1.0.0")
	.description(
		"CLI para generar c√≥digo en Golang y responder preguntas t√©cnicas usando un sistema RAG mejorado con doble LLM",
	)
	.argument("<query>", "Consulta en lenguaje natural")
	.action(async (query) => {
		console.log(`üîé Query original del usuario: "${query}"`);

		try {
			// 1Ô∏è‚É£ LLM 1 Reformula la query
			const refinedQuery = await reformulateQuery(query);
			console.log(`üìù Query optimizada para b√∫squeda: "${refinedQuery}"`);

			// 2Ô∏è‚É£ B√∫squeda en ChromaDB con la query reformulada
			const context = await fetchRelevantDocs(refinedQuery);
			console.log("‚úÖ Contexto encontrado en ChromaDB.");

			// 3Ô∏è‚É£ LLM 2 Responde la pregunta o genera c√≥digo basado en el contexto
			const response = await answerOrGenerateCode(query, context);
			console.log("\nüíª Respuesta generada:\n");
			console.log(response);
		} catch (error) {
			console.error("‚ùå Error:", error);
		}
	});

program.parse(process.argv);

// üìå 1Ô∏è‚É£ LLM 1: Reformula la query del usuario para optimizar la b√∫squeda
async function reformulateQuery(query) {
	console.log("ü§ñ LLM 1 optimizando la consulta...");

	const llm = new ChatOpenAI({
		modelName: "gpt-4o",
		openAIApiKey: OPENAI_API_KEY,
	});

	const prompt = `Eres un asistente experto en Golang con habilidades avanzadas en recuperaci√≥n de informaci√≥n.
Tu tarea es reformular la siguiente consulta de usuario en una b√∫squeda t√©cnica que optimice la recuperaci√≥n de informaci√≥n en la documentaci√≥n de Go.

Ejemplo:
Usuario: "C√≥mo manejar archivos en Go?"
B√∫squeda optimizada: "API para manipulaci√≥n de archivos en la librer√≠a est√°ndar de Go, incluyendo os.Open, os.ReadFile y bufio.Scanner."

Usuario: "${query}"
B√∫squeda optimizada:`;

	const response = await llm.invoke(prompt);
	return response.content; // Accede al contenido del mensaje
}

// üìå 2Ô∏è‚É£ Buscar informaci√≥n en ChromaDB con la query optimizada
async function fetchRelevantDocs(query) {
	console.log("üìÑ Consultando ChromaDB...");

	const client = new ChromaClient({ host: CHROMA_DB_URL });
	const embeddingFunction = new OpenAIEmbeddingFunction({
		openai_api_key: OPENAI_API_KEY,
		openai_model: "text-embedding-3-small",
	});

	const collection = await client.getCollection({
		name: "golang_docs",
		embeddingFunction: embeddingFunction,
	});

	// üî• Generar embedding de la query
	const queryEmbedding = await embeddingFunction.generate([query]);

	// üîé Buscar informaci√≥n relevante en ChromaDB con embeddings
	const results = await collection.query({
		queryEmbeddings: queryEmbedding, // ‚úÖ Usa embeddings expl√≠citamente
		nResults: 5,
	});

	console.log("üîç Resultados obtenidos:", results);
	return (
		results.documents?.[0]?.join("\n\n") ??
		"No se encontraron documentos relevantes."
	);
}

// üìå 3Ô∏è‚É£ LLM 2: Responde preguntas t√©cnicas o genera c√≥digo basado en el contexto
async function answerOrGenerateCode(query, context) {
	console.log("ü§ñ LLM 2 procesando la consulta con el contexto recuperado...");

	const llm = new ChatOpenAI({
		modelName: "gpt-4o",
		openAIApiKey: OPENAI_API_KEY,
	});

	const prompt = `Eres un experto en Golang con un profundo conocimiento del lenguaje y su ecosistema.
Tienes acceso a documentaci√≥n oficial de la librer√≠a est√°ndar de Go y puedes utilizarla para responder preguntas t√©cnicas con informaci√≥n precisa.

**Reglas de respuesta:**
- Dale prioridad al uso de la documentaci√≥n proporcionada.
- Si en la documentaci√≥n proporcionada existe la funcionalidad de la pregunta, no dir√°s que no existe.
- Si y solo si la documentaci√≥n no cubre la pregunta, responde usando tu conocimiento general de Go.
- Puedes usar tu base de conocimientos para complementar la respuesta.
- Responde de manera clara y concisa.
- Si la consulta requiere c√≥digo, genera un ejemplo funcional y bien estructurado.
- Si es necesario, explica el c√≥digo generado brevemente, pero sin ser redundante.
- No pidas al usuario que importe paquetes manualmente; incl√∫yelos en el c√≥digo cuando sea necesario.

---

üìå **DOCUMENTACI√ìN DISPONIBLE**
(Si la documentaci√≥n es relevante, √∫sala en la respuesta)

${context}

---

**Pregunta del usuario:**
${query}

üìå **Respuesta t√©cnica o c√≥digo en Go:**`;

	const response = await llm.invoke(prompt);
	return response.content; // Accede al contenido del mensaje
}
