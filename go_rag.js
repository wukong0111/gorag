import { Chroma } from "@langchain/community/vectorstores/chroma";
import { OpenAIEmbeddings } from "@langchain/openai";
import { ChatOpenAI } from "@langchain/openai";
import { program } from "commander";
import * as dotenv from "dotenv";

dotenv.config();

const CHROMA_DB_URL = process.env.CHROMA_DB_URL || "http://localhost:8000";
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

if (!OPENAI_API_KEY) {
	console.error("‚ö†Ô∏è  FALTA API KEY: Debes configurar OPENAI_API_KEY en tu .env");
	process.exit(1);
}

// üìå Configurar CLI con Commander
program
	.version("1.0.0")
	.description(
		"CLI para generar c√≥digo en Golang y responder preguntas t√©cnicas usando un sistema RAG mejorado con doble LLM",
	)
	.argument("<query>", "Consulta en lenguaje natural")
	.action(async (query) => {
		console.log(`üîé Query original del usuario: "${query}"`);

		try {
			// 1Ô∏è‚É£ LLM 1 Reformula la query
			const refinedQuery = await reformulateQuery(query);
			console.log(`üìù Query optimizada para b√∫squeda: "${refinedQuery}"`);

			// 2Ô∏è‚É£ B√∫squeda en ChromaDB con la query reformulada
			const context = await fetchRelevantDocs(refinedQuery);
			console.log("‚úÖ Contexto encontrado en ChromaDB.");

			// 3Ô∏è‚É£ LLM 2 Responde la pregunta o genera c√≥digo basado en el contexto
			const response = await answerOrGenerateCode(query, context);
			console.log("\nüíª Respuesta generada:\n");
			console.log(response);
		} catch (error) {
			console.error("‚ùå Error:", error);
		}
	});

program.parse(process.argv);

// üìå 1Ô∏è‚É£ LLM 1: Reformula la query del usuario para optimizar la b√∫squeda
async function reformulateQuery(query) {
	console.log("ü§ñ LLM 1 optimizando la consulta...");

	const llm = new ChatOpenAI({
		modelName: "gpt-4o",
		openAIApiKey: OPENAI_API_KEY,
	});

	const prompt = `Eres un asistente experto en Golang con habilidades avanzadas en recuperaci√≥n de informaci√≥n.
Tu tarea es reformular la siguiente consulta de usuario en una b√∫squeda t√©cnica que optimice la recuperaci√≥n de informaci√≥n en la documentaci√≥n de Go.

Ejemplo:
Usuario: "C√≥mo manejar archivos en Go?"
B√∫squeda optimizada: "API para manipulaci√≥n de archivos en la librer√≠a est√°ndar de Go, incluyendo os.Open, os.ReadFile y bufio.Scanner."

Usuario: "${query}"
B√∫squeda optimizada:`;

	const response = await llm.invoke(prompt);
	return response.content; // Accede al contenido del mensaje
}

// üìå 2Ô∏è‚É£ Buscar informaci√≥n en ChromaDB con la query optimizada
async function fetchRelevantDocs(query) {
	console.log("üìÑ Consultando ChromaDB...");

	const embeddings = new OpenAIEmbeddings({
		openAIApiKey: OPENAI_API_KEY,
		modelName: "text-embedding-3-small",
	});

	const vectorStore = new Chroma(embeddings, {
		collectionName: "golang_docs",
		url: CHROMA_DB_URL,
		collectionMetadata: {
			"hnsw:space": "cosine",
		},
	});

	// Buscar informaci√≥n relevante en ChromaDB
	const results = await vectorStore.similaritySearch(query, 5);
	return results.map((r) => r.pageContent).join("\n\n");
}

// üìå 3Ô∏è‚É£ LLM 2: Responde preguntas t√©cnicas o genera c√≥digo basado en el contexto
async function answerOrGenerateCode(query, context) {
	console.log("ü§ñ LLM 2 procesando la consulta con el contexto recuperado...");

	const llm = new ChatOpenAI({
		modelName: "gpt-4o",
		openAIApiKey: OPENAI_API_KEY,
	});

	const prompt = `Eres un experto en Golang con un profundo conocimiento del lenguaje y su ecosistema.
Tienes acceso a documentaci√≥n oficial de la librer√≠a est√°ndar de Go y puedes utilizarla para responder preguntas t√©cnicas con informaci√≥n precisa.

**Reglas de respuesta:**
- Usa la documentaci√≥n proporcionada si es relevante.
- Si la documentaci√≥n no cubre la pregunta, responde usando tu conocimiento general de Go.
- Responde de manera clara y concisa.
- Si la consulta requiere c√≥digo, genera un ejemplo funcional y bien estructurado.
- Si es necesario, explica el c√≥digo generado brevemente, pero sin ser redundante.
- No pidas al usuario que importe paquetes manualmente; incl√∫yelos en el c√≥digo cuando sea necesario.

---

üìå **DOCUMENTACI√ìN DISPONIBLE**
(Si la documentaci√≥n es relevante, √∫sala en la respuesta)

${context}

---

**Pregunta del usuario:**
${query}

üìå **Respuesta t√©cnica o c√≥digo en Go:**`;

	const response = await llm.invoke(prompt);
	return response.content; // Accede al contenido del mensaje
}
